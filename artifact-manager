#!/usr/bin/env python

"""
A script to manage a remote repository for overlaying artifacts (binary files) 
on top of a local folder (typically a checked-out Git local repository, but
not necessarily). Enables keeping versioned sets of artifacts, with their
position in the local tree, so that they can be downloaded, uploaded and
compared across versions.

Accepts as transport layers:
  - HTTP for read-only operations (listing/downloading) artifacts
  - a locally visible folder for R/W operations (above, plus uploading and
    version management)
  - An SMB R/W transport is in the works

"""

import os
import sys
import argparse
import errno
import subprocess
import stat
import re
import ast
import urllib2
import hashlib
import getpass
import glob
from datetime import datetime
from posixpath import join as posixjoin
from HTMLParser import HTMLParser
from ConfigParser import SafeConfigParser, NoSectionError, NoOptionError
from socket import gethostname, gethostbyname
from operator import itemgetter
from collections import defaultdict

from contextlib import closing
try:
    import cStringIO as StringIO
except ImportError:
    import StringIO
try:
    import smb.SMBConnection
    from nmb.NetBIOS import NetBIOS
    from mySMB import mySMBConnection
except ImportError:
    pass


# Default URLs for the artifacts repository (as R & R/W transports)
REPO_URL = ('http://artifacts.hi.inet',
            r'\\oriente.hi.inet\artifacts')
# SMB domain for authentication
DOMAIN = 'HI'

# Repository configuration: names of management files/dirs
VERSION = 3
OPTIONS = 'options'
INDEX = 'index'
REFS = 'refs'
BRANCHES = 'branches'
LOGS = 'logs'
OBJECTS = 'objects'
OPTIONS_SECTION = 'general'
CHUNK = 8192

# Default options
DEFAULT_OPTIONS = { 'version' : VERSION,
                    'git_ignored' : False,
                    'min_size' : 0,
                    'files' : (),
                    'extensions' : ('cache','dump','pkl',
                                    'mat',
                                    'rpm','deb',
                                    'mpg','mp3','mp4',
                                    'doc','docx','xls','xlsx','ppt','pptx',
                                    'ps','pdf','odt','ods','odp',
                                    'zip','tar','gz','bz2','rar') }

WHEREAMI = 'https://pdihub.hi.inet/paulo/artifact-manager'
README = """<html><body>
<p>
This folder contains a managed artifact repository, containing artifacts 
to deploy on top of a local folder (typically a git-managed working area, 
but not necessarily). Artifacts can be versioned, using the definition
of "artifact branches" as "sets of files that go together".
</p>
<p>
It is operated by means of the 'artifact-manager' script. Do not modify
files manually.
</p>
<p>
Note: though its structure has a certain resemblance with a Git
repository, it cannot be managed at all via Git commands.
</p>
<p>For further information, see:
<a href="{0}">{0}</a>
</p>
</body></html>""".format(WHEREAMI)


class MLStripper(HTMLParser):
    def __init__(self):
        self.reset()
        self.fed = []
    def handle_data(self, d):
        self.fed.append(d)
    def get_data(self):
        return ''.join(self.fed)

def strip_tags(html):
    """A function to remove all HTML tags from a text buffer"""
    s = MLStripper()
    s.feed(html)
    return s.get_data()

# ---------------------------------------------------------------------

class GenericError( Exception ):
    """An exception signaling a generic error in the processing"""
    def __init__( self, exception_type, msg=None, *args ):
        full_msg = exception_type + ': ' + msg if msg else exception_type
        super(GenericError,self).__init__(full_msg,*args)
        print self.args[0]
        sys.exit(1)

class TransportError( GenericError ):
    """An exception signaling a problem in the transport layer"""
    def __init__( self, msg=None, *args ):
        super(TransportError,self).__init__('Transport Error',msg,*args)

class InvalidArgumentError( GenericError ):
    """An exception signaling an invalid option"""
    def __init__( self, msg=None, *args ):
        super(InvalidArgumentError,self).__init__('Invalid Argument',msg,*args)


# ---------------------------------------------------------------------

def parse_unc( unc, subpath ):
    """
    Parse a Windows UNC path, possibly including host, user, password, domain 
    and share. The full specification of the UNC string is:

                \\domain\user:password@host\share\path

      @param unc (str): the UNC path. If it does not contain password
        information, it will be prompted to the console
      @param subpath (str): an optional subpath to add at the end of the 
        UNC path
      @return (dict): the result data, separated by component
    """
    m = re.match( r"""\\\\
                      (?: (?: (?P<domain>[-.\w]+) \\ )?
                              (?P<user>\w+)
                              (?: : (?P<pass>\w+) )?
                       @ )?
                      (?P<host>[-.\w]+)
                      \\
                      (?P<share>[^\\]+)
                      (?: \\
                          (?P<path>.+) )?""", unc, re.X )
    if not m:
        raise InvalidArgumentError( 'can\'t understand SMB UNC: %' % unc )
    d = m.groupdict()
    if d['user'] is None:
        d['user'] = os.getlogin()
    if d['domain'] is None:
        d['domain'] = DOMAIN
    if d['pass'] is None:
        d['pass'] = getpass.getpass("Please insert password for SMB user '{domain}\\{user}' on {host}: ".format( **d ) )
    d['path'] = os.path.join(d['path'], subpath) if d['path'] else subpath
    #print d
    return d


def mkpath_recursive(path):
    """Test a local path and, if it does not exist, create it recursively"""
    try:
        mode = os.stat( path ).st_mode
        if not stat.S_ISDIR(mode):
            raise InvalidArgumentError("parent path '"+str(path)+"' not a dir")
    except OSError as e:
        if e.errno != errno.ENOENT:
            raise
        (head,tail) = os.path.split( path )
        if head:
            mkpath_recursive( head )
        os.mkdir( path )


def git_find_info( what, repo_dir ):
    """
    Find information about a git repository. Try first calling the git
    command line directly; if that fails search within git internals
    """
    class StrippedFile(file):
        """A small helper class to read a config file with leading spaces"""
        def readline(self):
            return super(StrippedFile, self).readline().strip()

    # Range of git commands we can execute
    commands = { 'remote' : ['git','config','--get', 'remote.origin.url'],
                 'branch' : ['git','rev-parse','--abbrev-ref','HEAD'],
                 'ignored' : ['git','ls-files','-o','-i', '--exclude-standard']
               }

    # Execute git. If that fails, try digging into .git repo dir directly
    try:

        cmd = commands[what]
        if sys.version_info < (2,7):
            r = subprocess.Popen(cmd,cwd=repo_dir,stdout=subprocess.PIPE).communicate()[0]
        else:
            r = subprocess.check_output(cmd,cwd=repo_dir)
        output = r.rstrip()

    except Exception as e:
        if hasattr(e,'errno') and e.errno == errno.ENOENT:
            raise InvalidArgumentError("can't find directory: '%s'" % repo_dir)
        elif what == 'ignored':
            raise InvalidArgumentError("can't use --git-ignored option: git execution failed: " + str(e) )

        try:
            if what == 'remote':
                c = SafeConfigParser()
                with StrippedFile(os.path.join(repo_dir,'.git','config')) as f:
                    c.readfp(f)
                    output = c.get('remote "origin"','url')
            else:       # what == 'branch'
                with open(os.path.join(repo_dir,'.git','HEAD')) as f:
                    data = f.readline().rstrip()
                return data.split('refs/heads/')[-1]
        except Exception as e:
            if hasattr(e,'errno') and e.errno == errno.ENOENT:
                raise InvalidArgumentError("can't find git metadata in '%s'" % repo_dir)

    # Terminate output parsing
    if what == 'remote':
        (head,tail) = output.split(':')
        (repo_name,ext) = os.path.splitext( tail )
        return repo_name
    elif what == 'ignored':
        return output.splitlines()
    else:
        return output

# ---------------------------------------------------------------------
        

class WebTransport( object ):
    """
    A read-only transport using HTTP to access a remote repository
    """
    def __init__(self, url_base, subrepo='', verbose=0):        
        self._verbose = verbose
        self._base = posixjoin( url_base, subrepo )
        if not self._base.endswith('/'):
            self._base += '/'

    def get( self, source_name, dest ):
        """
        Get a file given its path, and store its contents in the 
        file-like object given.
        Any HTTP access or fetch error will generate an exception. To
        ensure the file is there before trying, use the exists() method.
        """
        u = urllib2.urlopen( self._base + source_name )
        meta = u.info()
        file_size = int(meta.getheaders("Content-Length")[0])
        file_name = source_name.split('/')[-1]
        if self._verbose > 1:
            print " .. downloading: %40s    size: %s" % (file_name, file_size)

        file_size_dl = 0
        block_sz = 8192
        while True:
            buffer = u.read(block_sz)
            if not buffer:
                break
            file_size_dl += len(buffer)
            dest.write(buffer)
            #status = r"%10d  [%3.2f%%]" % (file_size_dl, file_size_dl * 100. / file_size)
            #status = status + chr(8)*(len(status)+1)
            #print status,

    def exists( self, path ):
        """
        Test if a path exists in the repository, by sending a HEAD request
          @return (bool): \c True or \c False depending on the status received
            from the server
          @except TransportError on any access errors other than a 404
            (Not Found) status code.
        """
        url = self._base + path
        request = urllib2.Request(url)
        request.get_method = lambda : 'HEAD'
        try:
            response = urllib2.urlopen(request)
            return True
        except ValueError as e:
            raise TransportError( "can't access '%s' : invalid url" % url )
        except urllib2.HTTPError as e:
            if e.code == 404:
                return False
            raise TransportError( "can't access '%s' (%d): %s" % 
                                  (url,e.code,str(e.reason)) )
        except urllib2.URLError as e:
            raise TransportError( "can't access '%s' : %s" % 
                                  (url,str(e.reason)) )
            
# ---------------------------------------------------------------------

class BaseWTransport( object ):
    """
    A parent class providing some common functionality for R/W tranports
    """

    def folder_ensure( self, folder ):
        """Ensure a path exists in the repository. Create it if not"""
        if not folder:
            raise InvalidArgumentError('empty folder')
        t = self.check( folder )
        if t == 'D':
            return
        elif t == 'F':
            raise TransportError( "can't make folder: %s is a file" % folder )
        (parent,name) = os.path.split( folder )
        if parent:
            self.folder_ensure( parent )
        self.folder_create( folder )

    def update( self, source, destname ):
        """
        Create or update a file in the repository, as atomically as possible
        """
        self.put( source, destname + '.new' )
        self.rename( destname + '.new', destname )


class LocalTransport( BaseWTransport ):
    """
    A full R/W transport instance that uses a locally visible directory to 
    store and read all artifact data
    """

    def __init__( self, basedir, subrepo ):
        """
        Constructor
          @param basedir (str): local folder to use
          @param subrepo (str): name of the repository we are dealing with
        """
        if not basedir:
            raise InvalidArgumentError("Empty basedir in local transport")
        if not subrepo:
            raise InvalidArgumentError("Empty subrepo in local transport")
        self._basedir = os.path.join(basedir,subrepo)
        super(LocalTransport,self).__init__()

    def init_base( self ):
        """Ensure the base path for the repository exists"""
        mkpath_recursive( self._basedir )
        
    def exists( self, path ):
        """
        Test if a path exists in the repository
        """
        check = self.check( path )
        return check in ('F','D')

    def get( self, sourcename, dest ):
        """
        Read a file into a file-like destination.
        @param sourcename (str): name of the file in remote repo
        @param dest (file): an object with a write() method
        @return (bool): \c True if ok, \c False if the file does not exist
        """
        name = os.path.join(self._basedir,sourcename)
        try:
            with open(name, 'rb') as f:
                while True:
                    bytes = f.read( CHUNK )
                    if not bytes:
                        break
                    dest.write( bytes )
            return True
        except IOError as e:
            if e.errno == errno.ENOENT:
                return False
            raise
        
    def put( self, source, destname ):
        """
        Store a file. If a file with the same name existed, it is overwritten
        @param source (file): an object with a read() method
        @param destname (str): name of the destination file,
        relative to repo base directory
        """
        name = os.path.join(self._basedir,destname)
        with open(name, 'wb') as f:
            while True:
                bytes = source.read( CHUNK )
                if not bytes:
                    break
                f.write( bytes )

    def delete( self, filename ):
        """
        Delete a file
        """
        name = os.path.join(self._basedir,filename)
        os.unlink( name )

    def rename( self, oldname, newname ):
        """
        Rename a file into a new name and/or folder
        """
        oldname = os.path.join(self._basedir,oldname)
        newname = os.path.join(self._basedir,newname)
        os.rename( oldname, newname )

    def check( self, path ):
        """
        Given a path component, return 'F' for a file, 
        'D' for a directory, or \c None if the path does not exist
        """
        oldname = os.path.join(self._basedir,path)
        try:
            mode = os.stat( oldname ).st_mode
        except OSError as e:
            if e.errno == errno.ENOENT:
                return None
            raise
        return 'D' if stat.S_ISDIR(mode) else 'F' if stat.S_ISREG(mode) else '?'

    def folder_create( self, path ):
        """
        Make a folder in the repository, assuming all parent folders exist
        """
        os.mkdir( os.path.join(self._basedir,path) )

    def folder_list( self, path ):
        """
        Return the list of all components (files & folders) in a folder
        """
        return os.listdir( os.path.join(self._basedir,path) )


class SMBTransport( BaseWTransport ):
    """
    A full R/W transport connecting to a remote folder via a Windows
    share (SMB protocol), using the pysmb module
    **UNFINISHED WORK**
    (there are pending authentication problems against oriente.hi.inet)
    """
    def __init__( self, url, subrepo ):
        super(SMBTransport,self).__init__()
        d = parse_unc( url, subrepo )
        n = NetBIOS();  #r = n.queryName( d['host'] ); print r
        smb_name = n.queryIPForName( gethostbyname(d['host']) ); 
        #print "NAMES: ", smb_name
        if True:
            self.conn = mySMBConnection( d['user'], d['pass'], gethostname(), 
                                         smb_name[0], domain=d['domain'], 
                                         use_ntlm_v2 = False, 
                                         sign_options = smb.SMBConnection.SMBConnection.SIGN_WHEN_SUPPORTED,
                                         is_direct_tcp = False)
            r = self.conn.connect( gethostbyname(d['host']), 139 )
           #self.conn.close()
        else:
            self.conn = mySMBConnection( d['user'], d['pass'], gethostname(), 
                                         smb_name[0], domain=d['domain'], 
                                         use_ntlm_v2 = False, 
                                         sign_options = smb.SMBConnection.SMBConnection.SIGN_WHEN_SUPPORTED,
                                         is_direct_tcp = True)
            r = self.conn.connect( gethostbyname(d['host']), 445 )
        self.cdata = d

    def init_base( self ):
        """Ensure the base path for the repository exists"""
        pass

    def get( self, sourcename, dest ):
        path = os.path.join( self.cdata['path'], sourcename )
        self.conn.retrieveFile( self.cdata['share'], path, dest )

    def put( self, source, destname ):
        pass

    def delete( self, filename ):
        pass

    def rename( self, oldname, newname ):
        pass

    def check( self, path ):
        """
        Given a path component, return 'F' for a file, 
        'D' for a directory, or None if the path does not exist
        """
        pass

    def folder_create( self, path ):
        """
        Make a folder in the repository, assuming all parent folders exist
        """
        pass

    def folder_list( self, path ):
        """
        Return the list of all components (files & folders) in a folder
        """
        pass


# ---------------------------------------------------------------------
        

def open_single_transport( url, subrepo, verbose ):
    """Open a transport to a remote repo"""
    #print url
    if( url.startswith('http:') or url.startswith('https:') ):
        return WebTransport( url, subrepo, verbose )
    elif( url.startswith('\\') or url.startswith('smb:') ):
        return SMBTransport( url, subrepo )
    else:
        return LocalTransport( url, subrepo )

def open_transports( spec, subrepo, write=False, verbose=0 ):
    """Open one (R) or two (R & R/W) transports to a remote repo"""
    spec = spec.split(',')
    reader = open_single_transport( spec[0], subrepo, verbose )
    if not write:
        return reader
    if len(spec) == 1:
        spec.append( spec[0] )
    writer = open_single_transport( spec[1], subrepo, verbose )
    return (reader,writer)

def sha1_file( size, filename ):
    """Compute a hash over a file, using the same spec that Git uses"""
    s = hashlib.sha1()
    s.update("blob %u\0" % size)
    with open(filename,'rb') as f:
        while True:
            bytes = f.read(8192)
            if not bytes:
                break
            s.update(bytes)
    return s.hexdigest()  

def fix_path(path):
    """Normalize a local path, and ensure we use forward slashes"""
    result = os.path.normpath(path)
    if os.sep == '\\':
        result = result.replace('\\', '/')
    return result

def size_string(size):
    """Return a human-readable string for a size given in bytes"""
    suffixes = ['','K','M','G','T']
    suffixIndex = 0
    precision = int(size > 1048576)
    while size > 1024:
        suffixIndex += 1 #increment the index of the suffix
        size = size/1024.0 #apply the division
    return "%.*f%s"%(precision,size,suffixes[suffixIndex])

def item_string(entry,subdir,path=None):
    """Return the item description corresponding to an object, as a string"""
    start = 0 if subdir is None else len(subdir)
    if path is None:
        path = entry[3]
    return '  %s %6s %s' % (datetime.fromtimestamp(entry[0]).strftime('%Y-%m-%d %H:%M %z'), size_string(entry[1]), path[start:] )

def dict_to_set( c ):
    """
    Convert a dict holding lists of strings into a set, 
    joining keys & values
    """
    if c is None:
        return set()
    return set( ((k,l) for k,v in c.iteritems() for l in v ) )

def object_remote_location( name ):
    """Return the location of an object in the repository, as (path,basename)"""
    return (OBJECTS + '/' + name[:2], name[2:])

def write_options_to_cfg( obj, cfg ):
    """Convert the options stored in the object into a config object"""
    cfg.add_section( OPTIONS_SECTION )
    for n in DEFAULT_OPTIONS:
        cfg.set( 'general', n, str(getattr(obj,n)) )

def read_options_from_cfg( remote_cfg, command_line_options, obj ):
    """
    Insert config options into an object. First set from defaults, then
    override with the config of the remote repo, and finally override
    with command-line options
    """
    # Check version
    try:
        v = remote_cfg.getint(OPTIONS_SECTION,'VERSION') 
        if v > VERSION:
            raise InvalidArgumentError( 'incompatible repository version: '+str(v) )
    except NoSectionError:
        remote_cfg.add_section( OPTIONS_SECTION )
    except NoOptionError:
        pass
    # Fill in options
    for k in DEFAULT_OPTIONS:
        # Set default
        setattr(obj,k,DEFAULT_OPTIONS[k])
        # Override with remote config
        try:
            value = remote_cfg.get(OPTIONS_SECTION,k)
            setattr( obj, k, ast.literal_eval(value) )
        except NoOptionError:
            pass
        except (SyntaxError,ValueError) as err:
            raise TransportError( "Can't parse remote value for config option '"
                                  + k + "': " + value )
        # Finally, override with a command-line argument if defined
        v = getattr(command_line_options,k,None)
        if v is not None:
            setattr(obj,k,v)
    

# ---------------------------------------------------------------------


class ArtifactReader( object ):
    """
    A class to manage a remote artifact repository, only for read operations
    (list remote listings, check against local artifacts, sync local with 
    remote by downloading, get individual artifacts)
    """

    def __init__(self, options ):
        # Store some generic options
        self.verbose = options.verbose
        self.dry_run = options.dry_run
        self.subdir = options.subdir
        # Store the repository configuration from the options
        self._repo_config( options )
        # Fetch remote lists
        self.remote_branches = self._get_branches()     # name : logmsg
        self.remote_index = self._get_index()           # sha : [object spec]
        # Initialize local lists
        self.local_index = {}                           # sha : [object spec]
        self.local_artifacts = defaultdict( list )      # sha : [list of files]


    def _repo_connect( self, source, subrepo ):
        """Open transport for reading"""
        self.reader = open_transports( source, subrepo )
        

    def _repo_config( self, options ):
        """Prepare the configuration for the remote artifact repository"""
        # Open the remote repository
        self._repo_connect( options.server_url, options.repo_name )
        # Read remote options
        config = SafeConfigParser()
        if not self.reader.exists( OPTIONS ):
            if self.verbose:
                print "Warning: repository",options.repo_name,"not initialized"
        else:
            with closing(StringIO.StringIO()) as buffer:
                self.reader.get( OPTIONS, buffer )
                buffer.seek( 0 )
                config.readfp( buffer )
        # Set the options, from defaults, remote config and command-line
        read_options_from_cfg( config, options, self )
        #print self.__dict__


    def _get_index( self ):
        """Get the index of the remote repository"""
        index = {}
        if self.reader.exists( INDEX ):
            with closing(StringIO.StringIO()) as buffer:
                self.reader.get( INDEX, buffer )
                for line in buffer.getvalue().splitlines():
                    data = line.split(' ',4)
                    index[ data[0] ] = [ float(data[1]), int(data[2]), 
                                         int(data[3],8), data[4] ]
        return index


    def _get_branches( self, get_logs=False ):
        """Get the list of branches in the remote repository"""
        branchlist = set()
        if self.reader.exists( BRANCHES ):
            with closing(StringIO.StringIO()) as buffer:
                self.reader.get( BRANCHES, buffer )
                branchlist.update( buffer.getvalue().splitlines() )
        branches = {}
        if not self.reader.exists(LOGS) or not get_logs:
            return dict( [(b,'') for b in branchlist] )
        else:
            return dict( [(b,self.remote_get_log(b)) for b in branchlist] )


    def remote_get_log( self, branch_string, return_none=False ):
        """Get the log message for a branch"""
        name = LOGS + '/' + branch_string
        if not self.reader.exists( name ):
            return ''
        with closing(StringIO.StringIO()) as buffer:
            self.reader.get( name, buffer )
            data = buffer.getvalue()
        return data


    def remote_get_branch( self, branch_string, return_none=False ):
        """
        Get the list of artifacts in the remote repo that correspond to a given 
        branch
          @param branch_string (str): name of the branch to fetch
          @param return_none (bool): to return \c None if the branch does
            not exist (otherwise an exception is raised)
          @return (dict): all files in the branch, as a \t (key,path) dict
        """
        name = REFS + '/' + branch_string
        # Check the branch does exist
        if return_none and not self.reader.exists( name ):
            if self.verbose:
                print "Warning: branch '%s' not in remote repo" % branch_string
            return None
        # Read the branch list from the server
        with closing(StringIO.StringIO()) as buffer:
            r = self.reader.get( name, buffer )
            data = buffer.getvalue()
        # Construct the branch dict
        branch = defaultdict(list)
        prev = None
        for l in data.splitlines():
            f = l.split(' ',2)
            key = f[0]
            value = f[1] if len(f)>1 else self.remote_index[key][3]
            if key != '-':
                branch[key].append( value )
            else:
                if prev is None:
                    print "Error in remote repo: invalid branch spec for '%s'" % branch_string
                    return None
                branch[prev].append( value )
            prev = key

        return branch
        

    def remote_list_branches( self, current_branch='', logs=False ):
        """
        Print out the list of branches in the remote repo
        """
        if self.verbose:
            print "\n# Info: list remote branches"
        if logs:
            self.remote_branches = self._get_branches( True )
        for b in sorted(self.remote_branches.keys()):
            print '*' if b == current_branch else ' ',
            print b if not logs else "%s : %s\n" % (b, self.remote_branches[b])
        return True


    def list_artifacts( self, branch_string, local_basedir ):
        """
        Print out the list of artifacts in the remote repo that
        correspond to a given branch
        """
        if branch_string == '.':
            if not self.local_artifacts:
                self._local_collect_list( local_basedir )
            clist = self.local_artifacts
            index = self.local_index
        else:
            clist = self.remote_get_branch(branch_string,return_none=True)
            index = self.remote_index

        if clist is None:
            return False

        if self.verbose:
            print "\n# Info: list",
            if branch_string == '.':
                print "local artifacts"
            else:
                print "remote artifacts for '%s'" % branch_string

        for k,v in sorted( clist.iteritems(), key=lambda e : e[1] ):
            if self.subdir and not v.startswith(self.subdir):
                continue
            print item_string(index[k],self.subdir,v[0])
            for item in v[1:]:
                print '  %49s' % item 

        return True


    def _add_local_file( self, name, size=None ):
        """Add a local artifact file to our internal tables"""
        if size is None:
            size = os.path.getsize(name)
        visible_name = os.path.join(self.subdir,name) if self.subdir else name
        s = [os.path.getmtime(name), size, 0644, visible_name]
        k = sha1_file(size,name)
        self.local_index[k] = s
        self.local_artifacts[k].append( visible_name )


    def _local_collect_list( self, local_basedir ):
        """
        Get all artifacts in the local checked out repository, and populate 
        the object's structure
        """
        current = os.getcwd()
        os.chdir( local_basedir )
        try:
            if self.git_ignored:
                for fullname in git_find_info( 'ignored', '.' ):
                    self._add_local_file( fullname )
                return

            # Compile extensions
            artifact_ext = set( map(lambda s : s.lower() if s.startswith('.') 
                                    else '.'+s.lower(), 
                                    self.extensions) )

            # Add all full paths (taking care of expanding globs)
            full_files = set()
            for f in self.files:
                if any( c in f for c in '*?[]' ):
                    full_files.update( glob.glob(f) )
                else:
                    full_files.add( f )

            # Traverse the tree and add all matching files
            for root, dirs, files in os.walk( '.' ):

                # Remove the directory with the Git metadata
                try:
                    dirs.remove( '.git' )
                except ValueError:
                    pass

                # Push all the files that match the conditions
                for name in files:
                    fullname = fix_path( os.path.join(root,name) )
                    if os.path.islink( fullname ):
                        continue        # skip symbolic links to files


                    # Build the set of extensions for this file
                    e = name.lower().split(os.path.extsep)[1:]
                    ext = set( [ '.' + os.path.extsep.join(e[i:]) 
                                 for i in range(0,len(e)) ])

                    size = os.path.getsize(fullname)
                    #print fullname, ext, size

                    if (fullname in full_files or 
                        (not artifact_ext.isdisjoint(ext) and 
                         size > self.min_size)):
                        self._add_local_file( fullname, size )
        finally:
            os.chdir( current )


    def _compare_lists( self, collection1, collection2 ):
        """
        Compare two dicts of items. Use both the key (i.e. the SHA1 hash) and
        the value (i.e. the path) in the comparison. This way we check both file
        contents and file location.
        """
        c1 = dict_to_set( collection1 )
        c2 = dict_to_set( collection2 )
        both = c1 & c2
        only_c1 = c1 - c2
        only_c2 = c2 - c1
        #import pprint; pprint.pprint(c1); pprint.pprint(c2)
        return (both, only_c1, only_c2)


    def local_check_list( self, local_basedir, branch_string ):
        """
        Compare the local artifacts with the ones in the remote repo,
        and return the differences
          @param local_basedir (str): the name of the local folder
          @param branch_string (str): identifier for the branch in remote repo
          @return a tuple of \t (<result_lists>,<artifact_index>), where
             <result_lists> contains three lists:
               (<same files>, <files only in local>, <files only in remote>)
        """
        # Compose dicts for local files & remote files
        if not self.local_artifacts:
            self._local_collect_list( local_basedir )
        #local_dict = dict([(k,v[3]) for k,v in self.local_artifacts.iteritems()])
        remote_dict = self.remote_get_branch(branch_string,return_none=True)

        # Compare those dicts
        results = self._compare_lists( self.local_artifacts, remote_dict )

        # Prepare a dictionary containing all local & remote items
        # -- first put all local files
        all_artifacts = self.local_index.copy()
        # -- now add all remote artifacts that are not in local
        all_artifacts.update( dict( (item[0],self.remote_index[item[0]]) 
                                    for item in results[2] ) )

        return (results,all_artifacts)


    def _print_diff( self, lists, index ):
        """
        Print out lists of item differences
         @param lists (dict): the lists to print, indexed by name
         @param index (dict): the index of all itemts in the lists
        """
        for lnam,lval in lists.iteritems():
            if not lval:
                continue # empty list; do not print
            #import pprint; pprint.pprint(lval)
            # build the list of items, remmoving all not in selected subdir
            item_list = [ i for i in sorted( lval, key=itemgetter(1) )
                          if not self.subdir or i[1].startswith(self.subdir) ]
            if not item_list:
                continue # if none left, skip list
            print '**', lnam
            for i in item_list:
                print item_string( index[i[0]], self.subdir, i[1] )


    def _print_diff_old( self, results, names=('ok','LOC','SRV') ):
        """
        Print out the list of item differences
        Old listing format, with a single combined list labeled by status
        """
        status = {}
        for r in zip(results,names):
            status.update( dict( (item,r[1]) for item in r[0] ) )
        for k in sorted( status, key=itemgetter(1) ):
            print '%4s  %s' % (status[k], k[1] )


    def diff( self, branch1, branch2, show_all ):
        """
        Compare two branches, and print out the differences
          @param branch1 (str): the name of the 1st branch
          @param branch2 (str): the name of the 2nd branch
        """
        list1 = self.remote_get_branch( branch1, return_none=True )
        list2 = self.remote_get_branch( branch2, return_none=True )
        results = self._compare_lists( list1, list2 )
        if self.verbose:
            subd = " for subdir '%s'" % self.subdir if self.subdir else ''
            print "\n# Info: compare branches '%s' & '%s'%s" % (branch1,branch2,subd)
        lists = dict( zip( ('in both','only in '+branch1,'only in '+branch2),
                           results ) )
        if not show_all:
            del lists['in both']
        self._print_diff( lists, self.remote_index )
        return True


    def local_print_changes( self, local_basedir, branch_string, show_all ):
        """
        Print out a summary of the comparison between the local artifacts 
        and the contents in the remote repo
        """
        results, artifacts = self.local_check_list(local_basedir,branch_string)
        if self.verbose:
            print "\n# Info: check local artifacts against '%s'" % branch_string
            if self.subdir:
                print "# for subdir '%s'" % self.subdir

        # Do the old listing format (single-list)
        #self._print_diff_old( results )
        #return True

        # Make the lists we will print
        lists = dict( zip( ('in both','only in local','only in server'),
                           results ) )
        if not show_all:
            del lists['in both']

        # Print the lists
        self._print_diff( lists, artifacts )
        return True


    def _get_file( self, fileid, outname ):
        """
        Download an artifact into a local file
        """
        # Create the directory to put the file, if needed
        (head,tail) = os.path.split( outname )
        if head:
            mkpath_recursive( head )
        # Download the file
        source_path = posixjoin( *object_remote_location(fileid) )
        with open(outname,'wb') as f:
            self.reader.get( source_path, f )
        # Set permissions & modification time
        filedata = self.remote_index[fileid]
        os.chmod( outname, int(filedata[2]) )
        os.utime( outname, (-1, float(filedata[0])) )


    def download_artifacts( self, branch_string, local_basedir, remove_old ):
        """
        Download to the local folder all artifacts in remote repo that
        correspond to a given branch.
          @param local_basedir (str): the name of the local folder
          @param branch_string (str): identifier for the branch in remote repo
          @param remove_old (bool): whether to delete local artifact files not
            in the remote repo
        """
        if self.verbose:
            print "\n# Info: download artifacts for '%s'" % branch_string
            if self.subdir:
                print "# for subdir '%s'" % self.subdir
            if self.dry_run:
                print "** DRY RUN"

        if branch_string not in self.remote_branches:
            print "Branch '%s' does not exist in artifact repo" % branch_string
            return False

        # Get the lists of files, compose status for each file
        results, artifacts = self.local_check_list(local_basedir,branch_string)
        status = {}
        for r in zip(results,('ok','old','new')):
            status.update( dict( (item,r[1]) for item in r[0] ) )
            
        # Go over each artifact and perform the required action
        prefix = len(self.subdir) if self.subdir else None
        for k in sorted( status, key=itemgetter(1) ):

            if prefix is None:
                outname = k[1]
            elif k[1].startswith( self.subdir ):
                outname = k[1][prefix:]
            else:
                continue

            what = status.get(k)
            action = '' if self.dry_run else "[DOWN]" if what == 'new' else "[DEL]" if what == 'old' and remove_old else ''
            if self.verbose:
                print '%4s: %s %s' % (what, outname, action)
            if action == '[DOWN]':
                self._get_file( k[0], os.path.join(local_basedir,outname) )
            elif action== '[DEL]':
                os.unlink( os.path.join(local_basedir,outname) )

        return True



    def get( self, filename, branch, outname ):
        """
        Fetch a file from a branch in remote repo
        """
        if self.verbose:
            print "\n# Info: download remote artifact '%s' @ '%s'" % (filename,branch)
            if self.dry_run:
                print "** DRY RUN"
        files = self.remote_get_branch( branch, return_none=True )
        if files is None:
            print "Error: no files in branch '%s'" % branch
            return False        
        for k,v in files.iteritems():
            if v == filename:
                if not self.dry_run:
                    print "[DOWNLOADING]"
                    self._get_file( k, outname )
                return True
        print "Error: can't find the file in branch '%s'" % branch
        return False
                

    def get_cfg( self ):
        """
        Get the options in the remote repo
        """
        cfg = SafeConfigParser()
        write_options_to_cfg( self, cfg )
        if self.verbose:
            print "\n# Info: get options from remote repo"
        cfg.write( sys.stdout )


# ---------------------------------------------------------------------

class ArtifactManager( ArtifactReader ):
    """
    A class to manage a remote artifact repository, for both read
    operations (download artifacts, check & compare artifact listings)
    and write operations (initialize, upload artifacts)
    """

    def __init__( self, options ):
        # Parent constructor will read the remote repository metadata
        super(ArtifactManager,self).__init__( options )
        # Now initialize the repository if it happens to be empty
        if not self.writer.check( INDEX ) and not self.dry_run:
            self.repo_init( options )

    def _repo_connect( self, source, subrepo ):
        """Open transports for R/W"""
        (self.reader,self.writer) = open_transports( source, subrepo, 
                                                     write=True )

    def repo_init( self, options ):
        """
        Initialize a new repository: write the folders and initial files
        """
        if self.verbose:
            print "\n# Info: initializing repository",options.repo_name
        # Ensure the base folder for the repo is there
        self.writer.init_base()
        # Create the needed subfolders
        self.writer.folder_create( OBJECTS )
        self.writer.folder_create( REFS )
        # Create README, index & options files
        with closing(StringIO.StringIO(README)) as buffer:
            self.writer.put( buffer, 'README.html' )
        with closing(StringIO.StringIO(strip_tags(README))) as buffer:
            self.writer.put( buffer, 'README' )
        self.writer.put( StringIO.StringIO(), INDEX )
        self.put_cfg()


    def put_cfg( self ):
        """Write the config options file in the remote repo"""
        cfg = SafeConfigParser()
        write_options_to_cfg( self, cfg )
        if self.verbose:
            print "\n# Info: setting repository options in remote server"
            cfg.write( sys.stdout )
        if self.dry_run:
            print "** DRY RUN"
            return
        with closing(StringIO.StringIO()) as buffer:
            cfg.write( buffer )
            buffer.seek( 0 )
            self.writer.put( buffer, OPTIONS )

    def put_object( self, data_source, object_name ):
        dest_path = object_remote_location(object_name)
        self.writer.folder_ensure( dest_path[0] )
        self.writer.put( data_source, posixjoin(*dest_path) )

    def put_log( self, branch_string, msg ):
        """Set the log message for a branch"""
        dest_name = os.path.join( LOGS, branch_string )
        (head,tail) = os.path.split( dest_name )
        if head:
            self.writer.folder_ensure( head )
        with closing(StringIO.StringIO(msg)) as buffer:
            self.writer.update( buffer, dest_name )
        
    def put_branch_filelist( self, branch_string ):
        """Put in the remote repository the list of objects for one branch"""
        # Compose the final name & ensure the destination folder exists
        dest_name = os.path.join( REFS, branch_string )
        (head,tail) = os.path.split( dest_name )
        if head:
            self.writer.folder_ensure( head )
        # Construct the file list
        if self.version < 3:
            files = ( k for k in sorted(self.local_index.keys()) )
        else:
            files = list()
            for k,v in self.local_artifacts.iteritems():
                files.append( '%s %s' % (k,v[0]) )
                for a in v[1:]:
                    files.append( '- ' + a )
        # write it
        with closing(StringIO.StringIO( "\n".join(files) )) as buffer:
            self.writer.update( buffer, dest_name )


    def put_index( self ):
        buffer = StringIO.StringIO()
        for item in sorted(self.remote_index):
            v = self.remote_index[item]
            buffer.write( "{0} {1} {2} 0{3:o} {4}\n".format( item, *v ) )
        self.writer.update( StringIO.StringIO(buffer.getvalue()), INDEX )


    def rename_branch( self, branch, new_branch_name ):
        """Rename a branch in the remote server"""
        if branch not in self.remote_branches:
            print "Branch '%s' does not exist in artifact repo" % branch
            return False
        if self.verbose:
            print "\n# Info: Renaming branch '%s' to '%s'" % (branch,new_branch_name)
        if self.dry_run:
            return 
        # Rename the branch filelist
        oldname = os.path.join( REFS, branch )
        newname = os.path.join( REFS, new_branch_name )
        (head,tail) = os.path.split( newname )
        if head:
            self.writer.folder_ensure( head )
        self.writer.rename( oldname, newname )
        # Transfer the log message, if needed
        log = self.remote_get_log( branch )
        if log:
            newlog = os.path.join(LOGS,new_branch_name)
            self.writer.folder_ensure( os.path.split(newlog)[0] )
            self.rename( os.path.join(LOGS,branch), newlog )
        # Update the list of branches
        del self.remote_branches[branch]
        self.remote_branches[new_branch_name] = log
        self.put_branches_list()
        return True


    def put_branches_list( self ):
        """Write in the remote repo the list of existing branches"""
        buffer = StringIO.StringIO()
        buffer.write( "\n".join(sorted(self.remote_branches.keys())) )
        self.writer.update( StringIO.StringIO(buffer.getvalue()), BRANCHES )


    def upload_artifacts( self, local_basedir, branch_string, overwrite=False ):
        """
        Upload all artifacts in the local directory to the remote repository
          @param local_basedir (str): local directory containing artifacts
          @param branch_string (str): identifier for the branch to upload to
          @param overwrite (bool): if the branch already exists in the
            remote repository, upload will fail unless this is \c True
        """
        # Check if this branch already has a remote entry, and bark if so
        # and we're not in overwrite mode
        remote = self.remote_get_branch( branch_string, return_none=True )
        if remote is not None and not overwrite:
            if self.verbose:
                print "Error: branch", branch_string, "already exists in repository"
                print "Use --overwrite option to change it"
            return False
        # Collect all local artifact object & find out which ones are not yet 
        # in the remote side.
        self._local_collect_list( local_basedir )
        newf = dict( (sha,self.local_artifacts[sha])
                     for sha in self.local_artifacts 
                     if sha not in self.remote_index )
        if self.verbose:
            print "\n# Info: Uploading local artifacts to '%s'" % branch_string
            print "  total local artifacts: ", len(self.local_artifacts)
            print "  already in repo: ", len(self.local_artifacts) - len(newf)
            if self.dry_run: print "  ** DRY RUN"
            #print self.local_artifacts
        # Process each new file
        for k,v in newf.iteritems():
            if self.verbose:
                print "   ... uploading: ", ' '.join(v)
            if self.dry_run:
                continue
            # Send it to remote repo & add locally to index
            # Use just the 1st file (the same "object" may be in more than 
            # one position locally)
            with open( os.path.join(local_basedir,v[0])) as f:
                self.put_object( f, k )
            self.remote_index[k] = self.local_index[k]

        # Now upload the list of files for this branch and update remote indices
        if not self.dry_run:
            self.put_branch_filelist( branch_string )
            if branch_string not in self.remote_branches.keys():
                self.remote_branches[branch_string] = ''
                self.put_branches_list()
            if len(newf):
                self.put_index()
        return True




# ***************************************************************************

if __name__ == "__main__":


    gnric = argparse.ArgumentParser( add_help=False )
    gnric.add_argument('--verbose', '-v', type=int, default=1, help='Verbose mode')
    gnric.add_argument('--dry-run', action='store_true', help="don't modify files, locally or remotely" )
    gnric.add_argument('--server-url', '-u', default=','.join(REPO_URL),
    help='Base URL for the repository server (default: %(default)s)' )
    gnric.add_argument('--repo-name', '-r', help='set the name of repository to use from the server' )
    gnric.add_argument('--branch', '-b', help='set the name of the branch to operate with' )
    gnric.add_argument('--subdir', '-s', help='operate only on a subdir of the project' )
    gnric.add_argument('--project-dir', '-d', default=os.getcwd(), help='local folder to use as tree root (default: %(default)s)')

    gnric.add_argument('--extensions', '-e', help='extensions to consider as artifacts (default: '+','.join(DEFAULT_OPTIONS['extensions'])+')', default=None )
    gnric.add_argument('--files', '-f', help='files to add explicitly as artifacts (full path)', default=None, nargs='+' )
    gnric.add_argument('--min-size', type=int, help='minimum size in bytes of an artifact to be considered (default: ' +str(DEFAULT_OPTIONS['min_size'])+')', default=None )
    gnric.add_argument('--git-ignored', action='store_true', help='define as artifacts all files ignored by git in the local repo' )


    # Define & read command-line options
    parser = argparse.ArgumentParser( description="Manage binary artifacts against a versioned remote repository. See " + WHEREAMI)
    subp = parser.add_subparsers( dest='command', title='command',
                                  help='Use -h on the command for additional options')

    s1 = subp.add_parser( 'list', help='list the artifacts in remote repo', 
                          parents=[gnric] )

    s2 = subp.add_parser( 'diff', help='compare two artifact lists',
                          parents=[gnric]  )
    s2.add_argument('other_branch', metavar='other-branch', nargs='?',
                    help='name of the other branch to compare to, when not the local project dir' )
    s2.add_argument('--show-all', '-a', action='store_true',
                    help='show all files, not only the differences' )

    s4 = subp.add_parser( 'download', help='download artifacts from server into the local project dir', parents=[gnric]  )
    s4.add_argument('--delete-local', action='store_true', help='when downloading, remove from local directory the artifacts not present in the remote side (default: %(default)s)' )
    
    s5 = subp.add_parser( 'get', help='fetch a single artifact file from remote server', parents=[gnric]  )
    s5.add_argument( 'name', help='file to fetch' ) 
    s5.add_argument('--outname', '-o', help='output file name, when not the same name as the original file' )

    s6 = subp.add_parser( 'upload', help='upload the set of local artifacts to the current branch in remote repo', parents=[gnric]  )
    s6.add_argument('--overwrite', action='store_true', help='when uploading, overwrite the remote artifact definition for the current branch (default: %(default)s)' )

    s7 = subp.add_parser( 'branches', help='list all branches in remote repo',
                          parents=[gnric] )
    s7.add_argument('--log', '-l', action='store_true',
                     help='show branch log messages' )

    s8 = subp.add_parser( 'getoptions', parents=[gnric],
                          help='get configuration options from remote repo' )
    s9 = subp.add_parser( 'setoptions', parents=[gnric],
                          help='set configuration options in remote repo' )

    s10 = subp.add_parser( 'rename-branch', parents=[gnric],
                           help='rename a branch in remote repo' )
    s10.add_argument('new_name', metavar='new-name', 
                     help='new name of the branch' )

    s11 = subp.add_parser( 'getlog', parents=[gnric],
                           help='get the log message for this branch' )

    s12 = subp.add_parser( 'setlog', parents=[gnric],
                           help='set the log message for this branch' )
    s12.add_argument('msg', help='text for the log message' )


    args = parser.parse_args()
    #print args

    # If not given, find out the name of the repository & branch from the
    # name of the git repo checked out in the local folder, and the
    # current checked out branch
    if not args.repo_name:
        args.repo_name = git_find_info( 'remote', args.project_dir )
    if not args.branch:
        args.branch = git_find_info( 'branch', args.project_dir )
    #print args

    if args.subdir and not args.subdir.endswith('/'):
        args.subdir += '/'

    # Split extensions
    if args.extensions == '':
        args.extensions = []
    elif args.extensions is not None:
        args.extensions = args.extensions.split(',')

    # Instantiate the manager class
    mgr_class = ArtifactManager if args.command in ('upload','setoptions','rename-branch','setlog') else ArtifactReader
    mgr = mgr_class( args )

    # Do the operation
    if args.command == 'list':

        r = mgr.list_artifacts( args.branch, args.project_dir )

    elif args.command == 'branches':

        r = mgr.remote_list_branches( args.branch, args.log )

    elif args.command in ('diff','check'):

        if args.other_branch:
            r = mgr.diff( args.branch, args.other_branch, args.show_all )
        else:
            r = mgr.local_print_changes( args.project_dir, args.branch, 
                                         args.show_all )

    elif args.command == 'download':

        r = mgr.download_artifacts( args.branch, args.project_dir, 
                                    args.delete_local )

    elif args.command == 'get':

        if args.outname is None:
            args.outname = os.path.join( args.project_dir, args.name )
        r = mgr.get( args.name, args.branch, args.outname )

    elif args.command == 'upload':

        r = mgr.upload_artifacts( args.project_dir, args.branch, args.overwrite ) 

    elif args.command == 'comment':

        r = mgr.set_comment( args.branch, args.overwrite ) 

    elif args.command == 'setoptions':

        r = mgr.put_cfg()

    elif args.command == 'getoptions':

        r = mgr.get_cfg()

    elif args.command == 'getlog':

        if args.verbose:
            print "\n# Info: log message for branch '%s'" % args.branch
        msg = mgr.remote_get_log( args.branch )
        print msg if len(msg) else "[no log]"
        r = 0

    elif args.command == 'setlog':

        r = mgr.put_log( args.branch, args.msg )

    elif args.command == 'rename-branch':

        r = mgr.rename_branch( args.branch, args.new_name )

    else:

        print args.command, "not implemented yet"
        sys.exit(1)


    sys.exit( not r )
